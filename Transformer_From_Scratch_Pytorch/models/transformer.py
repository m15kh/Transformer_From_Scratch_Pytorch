import torch.nn as nn

def scaled_dot_product_attension(q, k, v):
    pass

class MultiHeadAttension()


    